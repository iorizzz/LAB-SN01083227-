{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765b6837-3165-4951-8442-33cacd75c692",
   "metadata": {},
   "source": [
    "\n",
    "with open('sample.txt', 'r', encoding='utf-8') as file:\n",
    "text_data = file.read()\n",
    "print(\"Raw Text:\\n\", text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47530d-741e-4132-b4c4-7c647725d63a",
   "metadata": {},
   "source": [
    "\n",
    "with open('stored_text.txt', 'w', encoding='utf-8') as file:\n",
    "file.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91298e64-eb40-41ef-98b2-4f229638a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews:\n",
      " 0    The product is amazing!\n",
      "1     Worst experience ever!\n",
      "Name: Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('reviews.csv')\n",
    "print(\"Reviews:\\n\", df['Review'].head())\n",
    "# Save the reviews column to a text file\n",
    "df['Review'].to_csv('stored_reviews.txt', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4e046-e8df-4a4e-aca0-24bda50b1514",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "import json\n",
    "# Read the JSON file\n",
    "with open('social_data.json', 'r', encoding='utf-8') as file:\n",
    "data = json.load(file)\n",
    "print(\"Extracted City:\", data['city'])\n",
    "# Store the extracted city to a file\n",
    "with open('stored_city.txt', 'w', encoding='utf-8') as file:\n",
    "file.write(data['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400f954-d43c-4838-a76c-6ab8158956c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "# Parse the XML file\n",
    "tree = ET.parse('news.xml')\n",
    "root = tree.getroot()\n",
    "for article in root.findall('article'):\n",
    "title = article.find('title').text\n",
    "print(\"Extracted Title:\", title)\n",
    "# Store the extracted title to a file\n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file:\n",
    "for article in root.findall('article'):\n",
    "title = article.find('title').text\n",
    "file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a420383b-8a56-44c6-9e25-e6bbf24c2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\emier\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e873ac-8750-4fb5-9a42-73a07f76a2a9",
   "metadata": {},
   "source": [
    "import PyPDF2\n",
    "# Read the PDF file\n",
    "with open('document.pdf', 'rb') as file:\n",
    "reader = PyPDF2.PdfReader(file)\n",
    "text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "# Print the extracted text\n",
    "print(\"Extracted PDF Text:\\n\", text)\n",
    "# Store the extracted text in a file\n",
    "with open('stored_pdf_text.txt', 'w', encoding='utf-8') as output:\n",
    "output.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf1f87fc-3da6-4fd7-870d-4b4bc307923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text saved to business_proposal_all.txt\n",
      "Extracted text from page 2 saved to business_proposal_page_2.txt\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from all pages of a PDF\n",
    "def extract_all_text(pdf_path, output_txt):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "    \n",
    "    with open(output_txt, 'w', encoding='utf-8') as output:\n",
    "        output.write(text)\n",
    "    print(f\"Extracted text saved to {output_txt}\")\n",
    "\n",
    "# Function to extract text from a specific page\n",
    "def extract_page_text(pdf_path, output_txt, page_num):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        if page_num < len(reader.pages):\n",
    "            text = reader.pages[page_num].extract_text()\n",
    "            with open(output_txt, 'w', encoding='utf-8') as output:\n",
    "                output.write(text)\n",
    "            print(f\"Extracted text from page {page_num + 1} saved to {output_txt}\")\n",
    "        else:\n",
    "            print(f\"Error: Page {page_num + 1} does not exist in {pdf_path}\")\n",
    "\n",
    "# Extract text from all pages\n",
    "extract_all_text('Business_Proposal.pdf', 'business_proposal_all.txt')\n",
    "\n",
    "# Extract text from only page 2 (index starts at 0, so page 2 is index 1)\n",
    "extract_page_text('Business_Proposal.pdf', 'business_proposal_page_2.txt', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f626c12-cf0e-48de-88cc-05fdc2809379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
